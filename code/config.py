CFG_VIT = {
    'model' : {'name': 'transformers.ViTForImageClassification',
               'weight': 'google/vit-base-patch16-224',
               'img_size' : 224,
               'num_classes' : 11014,
               'scale' : 32,
               'margin' : 0.8},
    'training' : {'batch_size':64,
                  'epochs' :50,
                  'optim' : 'torch.optim.AdamW',
                  'backbone_lr':4e-5,
                  'arcface_lr':5e-4,
                  'T_mult':2,
                  'T_0':500,
                  'T_up':1500,
                  'eta_min':1e-8,
                  'gamma':0.9,
                  'save_term':643,
                  'grad_clip':0.25},
    'path' : {'output' : '../output/image_encoder/',
              'df' : '../data/train.csv',
              'test_df' : '../data/test.csv',
              'image_dir' : '../data/',
              'model' : '../output/image_encoder/image_encoder_30epoch.pth',
              'submission':'../submission/'}
}


CFG_BERT = {
    'model' : {'name': 'transformers.BertModel',
               'weight': 'cahya/bert-base-indonesian-522M',
               'max_length': 256,
               'num_classes':11014,
               'scale' : 32,
               'margin' : 0.6},
    'training' : {'batch_size' : 32,
                  'epochs':50,
                  'optim' : 'torch.optim.AdamW',
                  'backbone_lr':1e-5,
                  'arcface_lr':5e-4,
                  'T_0':500,
                  'T_mult':2,
                  'T_up': 1500,
                  'eta_min':1e-8,
                  'gamma':0.9,
                  'save_term':643,
                  'grad_clip':0.25},
    'path' : {'output': '../output/text_encoder/',
              'df' : '../data/train.csv',
              'test_df' : '../data/test.csv',
              'model': '../output/text_encoder/text_encoder_10epoch.pth',
              'submission':'../submission/'}
    }